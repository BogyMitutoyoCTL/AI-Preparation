# AI-Preparation
Vorbereitung auf die Umsetzung von Machine Learning (eine Untermenge von k√ºnstlicher Intelligenz) f√ºr das Spiel "Snake".

Dieses Projekt entstand urspr√ºnglich als Teil der Berufsorientierung f√ºr Gymnasien (BOGY) f√ºr das [Leibnitz-Gymnasium in Rottweil](https://lg.rw.schule-bw.de/home/?page_id=11268) im Schuljahr 2019/2020. Nach Ausbruch des Corona-Virus wurde das BOGY offiziell abgesagt. Wir freuen uns, dass die Sch√ºler das Praktikum dennoch freiwillig fortf√ºhren wollten. Als Firmenpartner stand [Mitutoyo CTL in Oberndorf](http://www.mitutoyo-ctl.de/de/karriere/ausbildungundstudium) mit Hardware, R√§umlichkeiten und Ansprechpartnern zur Verf√ºgung.

Inspiration f√ºr dieses Projekt war das [Leibniz Forschungszentrum](https://lg.rw.schule-bw.de/home/?cat=120) mit einer Idee, die Bewegung von Ameisen vom Computer vorherzusagen. Die Original-Idee beinhaltete ein Terrarium mit echten Ameisen, Kamera usw. Eine solch reale Umgebung birgt jedoch Schwierigkeiten, die mit den Rahmenbedingungen eines Praktikums schlecht vereinbar sind, z.B.:

* wer k√ºmmert sich um die Ameisen? M√∂glicherweise sterben sie ausgerechnet alle am ersten Tag der Praktikumswoche.
* wie nehmen die Teilnehmer das Ergebnis samt Ameisen mit nach Hause, um es Eltern und Freunden zu zeigen?
* sind die Ergebnisse reproduzierbar? Wir k√∂nnen bei einer fehlerhaften Umsetzung nicht nochmal am gleichen Startpunkt begonnen.
* passt das Projekt in den Zeitrahmen?

Aus diesem Grund haben wir uns entschlossen, zwar ein Machine Learning Projekt durchzuf√ºhren, aber die Bedingungen zu unseren Gunsten anzupassen. Entstanden ist ein Snake-Spiel, bei dem der Computer selbst die Spielregeln erlernen soll und dann die richtigen Aktionen durchf√ºhrt.

# Projekt-Umgebung

## Software

Wir verwenden kostenlose Software: 

* das Betriebssystem [Raspbian](https://www.raspberrypi.org/downloads/raspbian/) f√ºr den Raspberry Pi 4.  Wir verwenden die Version mit 4GB Speicher, da wir f√ºr ein Experiment viel RAM ben√∂tigen.
* die Programmiersprache [Python](https://www.python.org/)
* die Entwicklungsumgebung [PyCharm von JetBrains](https://www.jetbrains.com/de-de/pycharm/) (Community Edition)
* die Bibliotheken [Tensorflow](https://www.tensorflow.org/), [Keras](https://keras.io/) und [OpenAI Gym](https://gym.openai.com/)
* die Versionsverwaltung [Git](https://git-scm.com/) mit dem Provider [Github](https://github.com/)
* dazu unter Windows den [Editor Notepad++](https://notepad-plus-plus.org/) und das Difftool [Winmerge](https://winmerge.org/?lang=de)

## Daten

Im Rahmen des Projekts erzeugen sich die Daten aus dem Spielverlauf selbst.

# Vorbereitung / Einf√ºhrung

Bei unserem Praktikum handelt es sich um ein erweitertes BOGY / erweitertes Praktikum. Das bedeutet, dass zus√§tzlich zur Praktikumswoche noch 6 Nachmittage zur Verf√ºgung stehen, an denen die Grundlagen vermittelt werden k√∂nnen. Dadurch l√§uft die Praktikumswoche einfach fl√ºssiger und die Sch√ºler bekommen auch echte Ergebnisse hin.

## Erster Nachmittag, 12.2.2020

Am ersten Nachmittag haben wir uns zun√§chst vorgestellt und dann durch die Firma gef√ºhrt, um die R√§umlichkeiten kennenzulernen.

Die [Firmenpr√§sentation](presentation/Firmenpr√§sentation.pptx) ging noch etwas dar√ºber hinaus und erkl√§rt unser Motto, nennt die von uns entwickelte Software, erkl√§rt das duale Studium und zeigt Beispiele von Praktikumsprojekten.

Wir haben uns die Hardware angeschaut, auf dem wir das Projekt durchf√ºhren m√∂chten. Es handelt sich um einen [Raspberry Pi 4](presentation/Raspberry%20Hardware.pptx), der Dank der Speichererweiterung auf 4 GB auch gr√∂√üere Datenmengen verarbeiten kann, wie sie bei Machine Learning auftreten.

Dann haben wir uns mit dem Thema der Berufsorientierung auseinandergesetzt. Das Spielprinzip ist vermutlich hinreichend bekannt: es handelt sich um ein Snake-Spiel. Die Schlange (gr√ºn) frisst mit ihrem Kopf (blau) einen Apfel (rot) und w√§chst dabei. Zum Gl√ºck sind wir hier nicht an f√§cher√ºbergreifenden Unterricht gebunden, ansonsten m√ºsste man sich fragen, seit wann Schlangen vegetarisch sind (Biologie), ob nicht Adam und Eva den Apfel gegessen haben, anstatt der Schlange (Religion) und ob Schlangen mit k√ºnstlicher Intelligenz ein Bewusstsein haben, und somit √ºberhaupt in Tierversuchen einsetzbar sind (Ethik).

Die von uns bereitgestellte Spieleumgebung ist bereits auf KI-Experimente vorbereitet, d.h. ein beliebiger Algorithmus kann in der Umgebung mehrere Spiele nacheinander ohne menschliches Zutun spielen. Zur Spieleumgebung gibt es eine Visualisierung, die folgenderma√üen aufgebaut ist:

* der linke Bereich liefert statistische Daten
  * gr√ºn: Daten zur Visualisierung, derzeit nur die aktuelle Visualisierungsgeschwindigkeit in Bildern pro Sekunde (fps; frames per second)
  * hellblau: Daten zum Training, d.h. mehrere Spiele √ºbergreifend
  * violett: Daten zum aktuell laufenden Spiel. Ein Teil dieser Daten k√∂nnte als Input f√ºr Neuronen dienen.
* der rechte Bereich visualisiert das Spielfeld
  * rot: das Futter (angeblich ein Apfel)
  * blau: der Kopf der Schlange
  * gr√ºn: K√∂rper der Schlange, wobei die hellere Teile fr√ºher verschwinden als dunklere Teile

Im Bild sieht man einen von Mitutoyo programmierten Algorithmus, der noch keine k√ºnstliche Intelligenz nutzt. Dabei handelt es sich bewusst um einen Algorithmus, der nicht mathematisch als perfekt bewiesen ist. Unsere KI wird sich mit diesem Algorithmus messen m√ºssen. Bei 1000 Spielen erreicht er eine L√§nge von bis zu 80 K√§stchen, was einer Abdeckung von 40% der Fl√§che entspricht. 

![Snake Spiel](images/Snake.png)

Hausaufgaben:

* Github Account einrichten, damit wir sp√§ter gemeinsam an einem Projekt arbeiten k√∂nnen

* Fotofreigabe von den Eltern ausf√ºllen und unterschreiben lassen

* der Whatsapp-Gruppe f√ºr das Praktikum beitreten

* bei Interesse unserem [Instagram Account](https://www.instagram.com/mitutoyoctlg/) folgen.

## Zweiter Nachmittag, 19.2.2020

Wie bereits am ersten Tag kurz vorgestellt, haben wir ein "Daily Scrum" Meeting durchgef√ºhrt. Die Themen im BOGY weichen etwas von den √ºblichen Fragen f√ºr Entwickler ab. Wir wollten wissen, ob die Hausaufgaben erledigt sind und ob es sonstige Vorkommnisse gab, die das BOGY betreffen k√∂nnten.

Bereits am ersten Nachmittag haben wir zum Schluss den Raspberry Pi in Betrieb genommen und die Oberfl√§che vom Betriebssystem Raspbian kennengelernt. Heute haben wir uns etwas mehr mit den Innereien von Linux besch√§ftigt: Die [Linux Pr√§sentation](presentation/Linux.pptx) erkl√§rt den grunds√§tzlichen Aufbau, ist allerdings theoretischer Natur. Daher haben wir diese Pr√§sentation gek√ºrzt, indem wir Teile in ausgeblendeten Folien versteckt haben. Die [Bash Pr√§sentation](presentation/Bash.pptx) zeigt, was man auf er Linux Kommandozeile alles tun kann und hat den deutlich h√∂heren Praxisanteil. 

Wir schlie√üen diese beiden Teile ab mit der Behauptung: wer ein guter Hacker werden m√∂chte, kommt um Linux nicht herum. (Der Begriff Hacker wird hier in seinem positiven Sinn als T√ºftler mit Sinn f√ºr kreativen Umgang mit Technik verstanden)

## Dritter Nachmittag, 4.3.2020

Wir starteten mit der [Einf√ºhrung in PyCharm](presentation/Pycharm.pptx). Da wir PyCharm bereits auf dem Raspberry Pi installiert hatten, haben wir den Installations-Teil √ºbersprungen (die Anleitung verbleibt in versteckten Folien) und haben uns ganz auf die Features dieser IDE (Integrated Development Environment) konzentriert.

Danach legten wir los mit den ersten Schritten in der [Programmiersprache Python](presentation/Python%20Einf√ºhrung.pptx), um Unterschiede zu anderen Programmiersprachen kennen zu lernen und mit der Syntax vertraut zu werden.

Hausaufgaben:

* Python 3 zu Hause installieren

* [PyCharm Community Edition](https://www.jetbrains.com/de-de/pycharm/download/#section=windows) zu Hause installieren

* bei Interesse eine mathematische [Aufgabe von Project Euler](https://projecteuler.net/archives) l√∂sen

## Vierter Nachmittag, 11.3.2020

Beim Standup Meeting haben wir uns erkundigt, ob die Hausaufgaben Probleme bereitet haben. Dann haben wir bei Folie 44 der [Python Pr√§sentation](presentation/Python%20Einf√ºhrung.pptx) weitergemacht, wo wir letztes Mal aus Zeitgr√ºnden aufgeh√∂rt haben.

Hinzu kam dann eine Einf√ºhrung in [Objektorientierung mit Python](presentation/Python%20Objektorientierung.pptx). Dort kamen wir bis Folie 17 und haben mehrere tausend Hunde (Objekte vom Typ Hund) das virtuelle Licht der virtuellen Welt erblicken lassen. Es gab auch f√ºr uns Neues zu erlernen, z.B. dass es Jack Russel Jack Parson Terrier Mischlinge gibt.

## F√ºnfter Nachmittag, 18.3.2020

Aufgrund des Corona-Virus fiel die Berufsorientierung schulweit aus. Auch die Mitutoyo CTL Germany GmbH befand sich komplett im Home Office. Wir haben unser Team gefragt, ob es an einer Fortf√ºhrung online interessiert w√§re. Alle vier Teilnehmer waren daf√ºr. Dar√ºber freuten wir uns sehr üòä. Als Plattform haben wir [GotoMeeting](https://www.gotomeeting.com/de-de/meeting/meeting-beitreten?sc_lang=de-de) verwendet. Davon hat unsere Firma Lizenzen, so dass wir unbegrenzt konferieren konnten.

Wir haben mit der [Objektorientierung mit Python](presentation/Python%20Objektorientierung.pptx) ab Folie 18 weitergemacht, d.h. gleich mit der n√§chsten Aufgabe, eine Klasse Quader zu erstellen.

Im Anschluss haben wir uns mit dem Thema [Versionskontrolle allgemein](presentation/Versionskontrolle.pptx) besch√§ftigt, bevor wir dann konkret auf Git eingegangen sind. F√ºr den heutigen Tag haben wir extra eine Pr√§sentation f√ºr [Git unter Windows](presentation/Git%20Grundlagen%20-%20Windows.pptx) angelegt. Normalerweise w√ºrden wir [Git f√ºr Linux](presentation/Git%20Grundlagen.pptx) erkl√§ren, da der Raspberry ein Linux Betriebssystem hat. Die Unterschiede halten sich in Grenzen. Es unterscheidet sich lediglich die Installation der Tools. 

Wir finden Versionskontrolle praktisch und k√∂nnen nur empfehlen, das auch privat einzusetzen, beispielsweise f√ºr Ausarbeitungen im Rahmen einer GFS (gleichwertige Feststellung von Sch√ºlerleistungen).

## Sechster Nachmittag, 25.3.2020

Der heutige Tag befasste sich mit dem Thema [K√ºnstliche Intelligenz](presentation/K√ºnstliche%20Intelligenz.pptx). Ebenfalls in einer Online-Session haben wir geschaut, wie der Stand der Technik bei k√ºnstlicher Intelligenz ist, wo sich maschinelles Lernen in der Informatik einordnet und welche Probleme es dabei geben kann.

Ebenfalls besprochen haben wir, wie wir in der Praktikumswoche verfahren m√∂chten. Dieser Vorschlag kam von uns:

* Wir treffen uns morgens um **9:00 Uhr** f√ºr eine gemeinsame Besprechung, ggf. mit Pr√§sentation oder Erkl√§rungen.

* Danach gibt es eine Programmieraufgabe, die jeder daheim implementieren kann.

* Bei Fragen und Problemen gibt es die M√∂glichkeit, die Betreuer bei Mitutoyo anzurufen.

* Von 12:00 bis 13:00 Uhr ist Mittagspause

* Um **13:00 Uhr** treffen wir uns wieder, um die Ergebnisse der Programmieraufgabe zu besprechen.

* Direkt im Anschluss folgt wieder eine Pr√§sentation o.√§., gefolgt von einer weiteren Programmieraufgabe, genau wie am Vormittag.

* Um **16:30 Uhr** kommen wir wieder gemeinsam zusammen, um die Aufgabe zu besprechen.

Da wir bei Mitutoyo nicht gen√ºgend GotoMeeting Lizenzen haben, um t√§glich drei Meetings online zu halten, haben wir die Firma [Discord](https://discordapp.com/) gefragt, ob wir f√ºr das Praktikum Discord auch kommerziell nutzen d√ºrfen. Wir freuen uns √ºber die Zusage.

# Praktikumswoche, 31.3. bis 3.4.2020

## Montag, 31.3.2020

### Erl√§uterung des bestehenden Codes

Da wir uns auf das Machine Learning konzentrieren wollen, hat Mitutoyo das Snake-Spiel bereits implementiert. √úber diese Implementierung haben wir uns einen √úberblick verschafft.

#### Snake

Der Kern des Programms, das Spiel, ist in der Klasse `Snake` untergebracht. Das Spiel akzeptiert 7 m√∂gliche Bewegungen:

* `north`, um nach oben zu laufen
* `east`, um nach rechts zu laufen
* `south`, um nach unten zu laufen
* `west`, um nach links zu laufen
* `turn left`, um in Laufrichtung der Schlange links abzubiegen
* `turn right`, um in Laufrichtung der Schlange rechts abzubiegen
* `straight`, um weiter geradeaus in Laufrichtung der Schlange zu laufen

Die Klasse `Snake` nutzt eine andere Klasse `Field`, um sich zu zeichnen. Dabei handelt es sich um ein zweidimensionales Array, das wir als Spielfeld bezeichnen. `Field` enth√§lt bereits die Farben, wie sie sp√§ter abgebildet werden sollen.

Normalerweise w√ºrde das Snake Spiel von einem Menschen mit einem Controller bedient. Das ist in unserem Fall unpraktisch. Daher gibt es um die Klasse `Snake` herum noch ein sogenanntes Gym (englisch *gymnasium* = Sporthalle), also einen Ort, in der die k√ºnstliche Intelligenz trainieren kann. Dieses Gym ist kompatibel zu der Definition eines Gym von OpenAI. Die Klasse daf√ºr bei uns hei√üt `SnakeGym`.

#### Algorithmen

Damit beim Programmieren von unterschiedlichen Strategien der Schlange weder das Gym, noch das Spiel selbst ge√§ndert werden muss, haben wir eine Klasse `Algorithm` definiert. Diese Klasse ist vorbereitet auf Machine Learning, d.h. sie hat Methoden und Eigenschaften, die wir am Anfang noch nicht brauchen, sondern erst, wenn wir tats√§chlich Machine Learning mit neuronalen Netzen betreiben. Mit dieser Klasse `Algorithm` ist es sehr einfach, selbst eine Idee zu verwirklichen, wie die Schlange sich bewegen soll.

Ein Beispiel f√ºr einen solchen Algorithmus ist `RotateForever`. Dieser Algorithmus basiert auf der Idee, dass Snake m√∂glichst lang gespielt werden soll. Die einfachste Art, ewig zu spielen ist, sich immer im Kreis zu drehen. Leider bekommt man daf√ºr keine Punkte. Die Implementierung dieser Idee ist beinahe trivial:

```python
from Algorithms.Algorithms import Algorithm
from GameData import GameData


class RotateForever(Algorithm):
    def __init__(self):
        super().__init__()

    def decide(self, info: GameData) -> str:
        return "turn left"
```

Die ersten Zeilen sind immer identisch. Lediglich die Funktion `decide()` muss angepasst werden.

Von diesen sehr einfachen Algorithmen haben wir einige zusammengestellt:

* `RotateForever`: dreht sich immer im Kreis
* `RandomChoice`: w√§hlt eine Zufallsaktion, also ob man einfach blind auf dem Controller herumdr√ºckt

#### Entscheidungsgrundlagen f√ºr Algorithmen

Damit man sich nicht blind f√ºr eine Aktion entscheiden muss, bekommt man f√ºr die Entscheidung ein paar Grundlagen, und zwar im Parameter `info` vom Typ `GameData`. Darin sind allerhand Informationen zu finden, die man f√ºr Entscheidungen braucht:

* `head_x` und `head_y`: wo der Kopf der Schlange sich befindet
* `snake_length`: L√§nge der Schlange
* `direction`: Aktuelle Laufrichtung der Schlange
* `food_x` und `food_y`: wo sich das Futter befindet
* `food_direction`: Richtung, in der sich das Futter befindet. Die Winkel sind dabei wie folgt:
  ![Richtungen](images/directions.png)
* `food_distance_in_steps`: Schritte bis zum Futter (k√ºrzester Weg, ohne Ber√ºcksichtigung von Hindernissen)
* `air_line_distance`: Abstand zum Futter in K√§stchen (diagonal, Pythagoras)
* `walldistance_`...: Abstand zur Wand (vom Kopf aus)
* u.a.

Ebenfalls n√ºtzlich sind einige Funktionen:

* `can_move_to(x,y)`: findet heraus, ob an diese Position gelaufen werden kann, ohne zu sterben

* `body_age(x,y)`: findet heraus, wie bald sich der K√∂rper an dieser Stelle hier wegbewegt

* `is_body(x,y)`, `is_food(x,y)` und `is_head(x,y)`: um abzufragen, um welche Sorte K√§stchen es sich handelt

Das Spielfeld ist dabei folgenderma√üen aufgebaut:

‚Äã    ![Aufbau des Spielfelds](images/playground.png)

Diese Richtung der Achsen ist in der Bildverarbeitung √ºblich. Euer Monitor hat z.B. ebenfalls die Ecke P(0|0) oben links.

#### Die Anzeige

Damit wir eine h√ºbsche Anzeige mit allerhand Statistik bekommen, gibt es die Klasse `Visualization`. Diese nutzt die Bibliothek PyGame, um ein Fenster zu zeigen.

Die Daten der Statistik kommen aus der Klasse `TrainingData`.

#### Zum lauff√§higen Programm zusammengestellt

Das Programm `main.py` f√ºgt alle Dinge zusammen: 

* es baut das Gym auf
* es zeigt alle Algorithmen an und l√§sst den Benutzer einen ausw√§hlen
* es l√§sst den Algorithmus in einigen Runden (`max_epochs`) spielen
* zeigt am Ende die Statistik auf der Konsole an.

Auch das Programm `main.py` ist schon auf Machine Learning vorbereitet. Deshalb gibt es dort auch schon ein Belohnungssystem vom Typ `RewardSystem` und einen Algorithmus f√ºr Zufallsentscheidungen, aus denen die KI sp√§ter lernen wird.

Die Klassen `Snake`, `Field`,`SnakeGym`, `Algorithm`, `RotateForever`, `RandomChoice` und `GameData` m√ºssen im Laufe des Praktikums nicht ge√§ndert werden.

### Ausprobieren

Wir haben gemeinsam ausprobiert, was die Ergebnisse des `RandomChoice` Algorithmus sind. Unsere sp√§teren Ergebnisse sollten auf jeden Fall besser sein als Zufall.

Ergebnisse nach 100 Epochen (100 Spielen):

* T‚∏ª: bestes Ergebnis: 5, max. gelaufene Schritte: 107, Gesamtmenge gegessen: 12, Gesamtanzahl Schritte: 3003
* D‚∏ª: bestes Ergebnis: 4, max. gelaufene Schritte: 118, Gesamtmenge gegessen: 18, Gesamtanzahl Schritte: 3269
* B‚∏ª: bestes Ergebnis: 4, max. gelaufene Schritte: 118, Gesamtmenge gegessen: 9, Gesamtanzahl Schritte: 3247
* N‚∏ª: bestes Ergebnis: 4, max. gelaufene Schritte: 105, Gesamtmenge gegessen:7, Gesamtanzahl Schritte: 3138

### Aufgabe: schreibe einen Algorithmus

Die Aufgabe f√ºr diesen Vormittag ist, einen eigenen Algorithmus zu schreiben, der hoffentlich schon besser funktioniert als der Algorithmus, der per Zufall entscheidet. Dazu verwenden wir noch keine KI. Wir m√∂chten zun√§chst herausfinden, wie schwierig es eigentlich ist, gut Snake zu spielen.

Das Grundger√ºst sieht so aus:

```python
from Algorithms.Algorithms import Algorithm
from GameData import GameData


class B‚∏ª(Algorithm):  # Passe den Klassen-Namen hier an
    def __init__(self):
        super().__init__()

    def decide(self, info: GameData) -> str:
        # Programmiere hier
```

## Montag Nachmittag

Am Nachmittag haben wir wieder online konferiert und unsere Erfahrungen mit dem Programmieren eines eigenen Algorithmus besprochen.

### Ausprobieren

Wir haben gemeinsam verglichen, was die Ergebnisse unserer eigenen Algorithmen sind.

* unser Student: bestes Ergebnis: 56 in 80 Spielen, max. gelaufene Schritte: 925, Gesamtmenge gegessen: ca. 2100, Gesamtanzahl Schritte: ca. 30000, Anzahl der `if` Anweisungen: 12.
  Und er wird auch nicht mehr besser: gleiches Ergebnis bei 1000 Spielen / 24703 Essen / 379.473 Schritten
* D‚∏ª: bestes Ergebnis 15 in 100 Spielen, max. Schritte 604, Gesamtmenge Futter: 329, Gesamt-Schritte: 18957, Anzahl der `if`-Anweisungen: 3
* B‚∏ª: bestes Ergebnis 5 in 100 Spielen, max. Schritte 205, Gesamtmenge Futter: 22, Gesamt-Schritte: 12727, Anzahl der `if`-Anweisungen: 5
* N‚∏ª: bestes Ergebnis 11 in 100 Spielen, max. Schritte 412, Gesamtmenge Futter: 76, Gesamt-Schritte: 8940, Anzahl der `if`-Anweisungen: 8

In der Regel kann man erkennen, dass das Ergebnis besser wird, je mehr Bedingungen oder Situationen im Algorithmus ber√ºcksichtigt werden. Das dr√ºckt sich h√§ufig durch die Anzahl der `if`/`elif` Abfragen aus.

### Spaghetti-Code?

Gleichzeitig merkt man beim Programmieren aber auch, dass es immer schwieriger wird, die richtige Stelle zu finden, an der man noch weiter verbessern kann. Bei Programmierern mit wenig Erfahrung kann das schnell zu so genanntem Spaghetti Code f√ºhren. Als Spaghetti Code wird Quellcode bezeichnet, der in sich verstrickt ist. 

Bei Spaghetti Code ist oft nicht klar, was alles passiert, wenn man an einer Stelle etwas √§ndert. Und man muss sich fragen, ob man selbst das Programm noch verstehen w√ºrde, wenn man es in einem halben Jahr noch einmal liest.

Damit das nicht passiert, haben sich ein paar Regeln und Konzepte gebildet. Einerseits gibt es so genannte Entwurfsmuster (engl. *patterns*), mit denen man bestimmte Probleme l√∂sen kann, zum anderen gibt es eine Initiative namens *Clean Code*, die zumindest Hinweise gibt, was man tun bzw. nicht tun sollte. Und wenn man dann nicht weiter wei√ü, sollte man einen Entwickler fragen, der mehr Erfahrung hat und vielleicht einen gute Tipp auf Lager hat, wie der Spaghetti Code ordentlicher aussehen k√∂nnte.

Die Pr√§sentation [Von der Spaghetti-Schlange zu Q-Tables](presentation/Von%20der%20Spaghetti-Schlange%20zu%20Q-Tables.pptx) stellt die Problematik vor und schl√§gt eine L√∂sung vor.

### Aufgabe: Umrechnung einer Situation in eine Nummer

Die Aufgabe ist bereits in der Pr√§sentation beschrieben: schreibe eine Funktion, die 

* einen Ausschnitt aus dem Spielfeld um den Kopf herum in Betracht zieht
* die Situation aus leeren und belegten Feldern in eine Zahl umrechnet
* und dabei bestimmte Felder ausmaskieren (auslassen) kann

## Dienstag, 31.3.2020

### Aufgabe: Entscheidungen sammeln

Wir haben ein Programm geschrieben, das Entscheidungen f√ºr bestimmte Situationen aufzeichnen und abspeichern kann. Dieses Programm ist kompatibel zu der Art und Weise, wie wir die Situation in eine Nummer umrechnen. Allerdings gilt es nun, 2^8 Felder * 5 Richtungen, also f√ºr 1280 F√§lle die Entscheidungen einzusammeln. Diese Arbeit teilen wir uns. 

Die grafische Oberfl√§che daf√ºr sieht folgenderma√üen aus:

 ![Entscheidungs-Recorder](images/decisionrecorder.png)

Zu sehen ist ein 3x3 Ausschnitt aus dem Spielfeld. Der dunkelrote Winkel zeigt an, in welcher Richtung sich das Futter befindet. In diesem Fall liegt das Futter auf jeden Fall s√ºdlich, es k√∂nnte aber zus√§tzlich noch ein bisschen √∂stlich liegen, vielleicht aber auch westlich. Dass der rote Ausschnitt eher nach Westen zeigt, ist dabei kein Anzeichen f√ºr eine h√∂here Wahrscheinlichkeit, dass das Futter im Westen liegt.

Welche Aktion die Schlange in dieser Situation ausl√∂sen soll, bestimmst Du. Folgende Kriterien sind zu beachten:

* Die Schlange soll keinesfalls sterben. Fahre also nicht in den Schwanz der Schlange.
* Die Schlange sollte m√∂glichst schnell zum Futter kommen.

Da der rote Bereich sowohl westlich als auch √∂stlich liegt, ist weder Osten noch Westen im gezeigten Fall eine gute Wahl. Wenn die Schlange allerdings nach S√ºden f√§hrt, wird irgendwann die Auspr√§gung zwischen Ost oder West deutlicher:

* Verschiebung nach Osten, falls das Futter tats√§chlich √∂stlich lag:
  ![](images/ostverschiebung.png)

* Verschiebung nach Westen, falls das Futter tats√§chlich westlich lag:
  ![](images/westverschiebung.png)

Da das Programm alle M√∂glichkeiten durchgeht, k√∂nnen Situationen angezeigt werden, die im Spiel nie vorkommen k√∂nnen, beispielsweise:

 ![Unm√∂gliche Situation](images/impossible.png)

Es muss mindestens ein gr√ºnes K√§stchen an das blaue K√§stchen anschlie√üen, da die Schlange nicht diagonal laufen kann. F√ºr diesen Fall ist der Button "Impossible" gedacht.

Beachte aber, dass nicht alle diagonal aussehenden Felder unm√∂glich sind. Folgendes Feld beispielsweise ist legal:

 ![M√∂gliches Spielfeld](images/possible.png)

weil das Spielfeld so aussehen k√∂nnte:

 ![](images/possible_field.png)

Damit wir eine gegenseitige Kontrolle haben, sollten sich die F√§lle √ºberlappen. Somit ergeben sich f√ºr jeden Sch√ºler 640 Entscheidungen.

* D‚∏ª: Situation 0 bis 640

* B‚∏ª: Situation 0 bis 640

* N‚∏ª: Situation 641 bis 1280

* L‚∏ª: Situation 641 bis 1280

## Dienstag Nachmittag

Aufgabe: Algorithmus programmieren, der die aufgezeichneten Entscheidungen aus den JSON Dateien einliest und dann gem√§√ü diesen Entscheidungen spielt.

Diese Aufgabe konnten wir mit den Daten vom Vormittag gut umsetzen. Dabei haben wir noch eine Endlosschleife erkannt, die durch eine Folge von Entscheidungen reproduziert werden konnte. Ein kurzer Eingriff in diese Datei behob die Schleife und die Schlange erreichte sehr gute Ergebnisse.

Ein kurzes Video war noch am Abend [auf Instagram zu sehen](https://www.instagram.com/p/B-aXMAdKDBe/).

## Mittwoch, 1.4.2020

Am Mittwoch Vormittag haben wir den Code aufger√§umt, damit wir ihn leichter anpassen k√∂nnen.

Dabei haben wir erste Prinzipien des [Clean Code](https://clean-code-developer.de) angewandt und sog. Refactorings ausgef√ºhrt, die uns helfen, unseren Code besser verst√§ndlich zu machen.

Wir haben weiterhin einen Teil des Vormittages damit verbracht zu verstehen, warum sich unsere Projektumgebung immer wieder in die Haare bekommt, obwohl wir bereits die [Empfehlungen von Jetbrains](https://www.jetbrains.com/help/pycharm/creating-and-managing-projects.html) ber√ºcksichtigt haben. Schlie√ülich haben wir uns bei [Gitignore.io](https://www.gitignore.io/) eine andere `.gitignore`-Datei [generiert](https://www.gitignore.io/api/python,windows,virtualenv,pycharm+all), die hoffentlich unsere Probleme l√∂st.

## Mittwoch Nachmittag

Am Nachmittag waren wir dann soweit, dass wir unseren Code so √§ndern konnten, dass wir weg von vordefinierten Entscheidungen in Richtung Machine Learning (ML)  gehen konnten.

Wir haben dazu unsere 2-dimensionale Struktur so √ºberarbeitet, dass eine 3D-Struktur entstanden ist, die Werte f√ºr die Zuversichtlichkeit von Aktionen aufnimmt. Diese Werte haben wir mit einem Mittelwert von 0,5 initialisiert und in der Feedback-Phase entweder erh√∂ht oder erniedrigt, je nach dem, ob eine Aktion erfolgreich war oder sich schlecht auf die Lebensdauer der Schlange auswirkte.

Der letzte Schritt des Tages bestand darin, die 3D-Struktur abzuspeichern und wieder zu laden, so dass die Schlange nicht immer von Neuem anfangen muss zu lernen. Hier stellte sich das Dateiformat JSON als zu langsam heraus, um in jeder Runde gespeichert zu werden. Schlie√ülich sind wir bei `pickle` gelandet und haben erst nach einer gewissen Anzahl Lernschritten gespeichert, anstatt am Ende jedes Spiels. Die Dateigr√∂√üe betr√§gt bei einem 5x5 Spielfeld und 5 Blickrichtungen ca. 230 MB.

## Donnerstag, 2.4.2020

Wir haben kurz besprochen, welchen Typ Machine Learning wir bisher angewandt haben: es handelte sich um [Q-Learning (engl. Wikipedia)](https://en.wikipedia.org/wiki/Q-learning) mit der Strategie [SARS (Pr√§sentation)](presentation/SARS.pptx), einem Vorg√§nger von [SARSA (engl. Wikipedia)](https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action).

Die besten Ergebnisse unserer Implementierung waren:

D‚∏ª: L√§nge 46 nach 11.414.612 Schritten in 100.000 Spielen, bei einer Gesamtmenge von 1.068.307 gegessenem Futter. Trainingsdauer: 5:25h

B‚∏ª: L√§nge 45

Wir haben dann diskutiert, welche M√∂glichkeiten es noch geben k√∂nnte, um bessere / andere Ergebnisse zu erzielen. Das w√§ren:

* Wir k√∂nnten die Trainingsdauer verl√§ngern. Es ist anzunehmen, dass noch nicht alle m√∂glichen 5.000.000 M√∂glichkeiten ausreichend von der Schlange erkundet wurden.
* Wir k√∂nnten das Sichtfeld und die Blickrichtungen anpassen, d.h. den State √§ndern. Siehe hierzu auch die Pr√§sentation [SARS](presentation/SARS.pptx)
* Hin und wieder zuf√§llige Aktionen ausf√ºhren, um neue Wege zu entdecken, die die Schlange noch nie beschritten hat.
  Dieser Ansatz ist im Machine Learning bekannt und wird √ºber die Variable Œµ (Epsilon) gesteuert.
* Wir k√∂nnten die Aktionen nicht gleichm√§√üig mit 0.5 vordefinieren, sondern Zufallswerte nutzen.
  Bei neuronalen Netzen ist dies der Fall.
* Wir k√∂nnten die Belohnungen und Bestrafungen anders verrechnen oder das Belohnungssystem anpassen. Beispielsweise haben wir die Schlange nicht bestraft, wenn sie vom Futter wegl√§uft.
* Die letzte Aktion eines Spiels f√ºhrt zwar zum unmittelbaren Tod der Schlange und wird bestraft. Die fatale Entscheidung wurde vielleicht jedoch schon zuvor getroffen, als die Schlange z.B. in eine Sackgasse lief. Die "Bestrafung" f√ºr den Tod der Schlange k√∂nnte auf die vorherigen Aktionen √ºbertragen werden.
  Auch dieser Ansatz ist bekannt. Es handelt sich um die Erweiterung von SARS auf SARSA. Das Prinzip √§hnelt ein wenig der [Backpropagation (engl. Wikipedia)](https://de.wikipedia.org/wiki/Backpropagation), wobei dieser Begriff f√ºr neuronale Netze reserviert ist, die wir nicht einsetzen.
* Wir k√∂nnten aufh√∂ren, weitere Erfahrungen f√ºr eine Situation zu verarbeiten, falls f√ºr diese Situation schon eine gewisse Menge Erfahrungen gesammelt wurden. Das k√∂nnte verhindern, dass gute Entscheidungen aus der Anfangsphase sp√§ter revidiert werden.

All diese M√∂glichkeiten k√∂nnte man ausprobieren, sofern man gen√ºgend Zeit h√§tte. Eine √§hnliche Situation gibt es sp√§ter auch bei neuronalen Netzen. Dort nennt man das Hyper-Parameter.



